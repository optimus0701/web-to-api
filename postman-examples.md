# Postman Examples - WebAI-to-API

H∆∞·ªõng d·∫´n chi ti·∫øt s·ª≠ d·ª•ng t·∫•t c·∫£ API endpoints v·ªõi Postman.

---

## üìã M·ª•c L·ª•c

- [C·∫•u H√¨nh Chung](#c·∫•u-h√¨nh-chung)
- [1. /v1/chat/completions (OpenAI-compatible)](#1-v1chatcompletions)
- [2. /gemini (New Session)](#2-gemini)
- [3. /gemini-chat (Persistent Session)](#3-gemini-chat)
- [4. /translate](#4-translate)
- [5. /v1beta/models/{model} (Google API)](#5-v1betamodelsmodel)
- [Postman Collection](#postman-collection)

---

## C·∫•u H√¨nh Chung

### Base URL
```
http://localhost:6969
```

### Headers (T·∫•t c·∫£ requests)
```
Content-Type: application/json
```

### Models Gemini C√≥ S·∫µn
- `gemini-3.0-pro` - M·∫°nh nh·∫•t, m·ªõi nh·∫•t
- `gemini-2.5-pro` - C√¢n b·∫±ng t·ªët
- `gemini-2.5-flash` - Nhanh nh·∫•t (m·∫∑c ƒë·ªãnh)

---

## 1. /v1/chat/completions

**OpenAI-compatible endpoint** - Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng cho h·∫ßu h·∫øt use cases.

### 1.1. Request ƒê∆°n Gi·∫£n

**Method:** `POST`  
**URL:** `http://localhost:6969/v1/chat/completions`

**Body:**
```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "user",
      "content": "Xin ch√†o! B·∫°n l√† ai?"
    }
  ]
}
```

**Response:**
```json
{
  "id": "chatcmpl-1735707600",
  "object": "chat.completion",
  "created": 1735707600,
  "model": "gemini-2.5-flash",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Xin ch√†o! T√¥i l√† Gemini, m·ªôt m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "total_tokens": 0
  }
}
```

---

### 1.2. V·ªõi System Prompt

**Body:**
```json
{
  "model": "gemini-2.5-pro",
  "messages": [
    {
      "role": "system",
      "content": "B·∫°n l√† m·ªôt chuy√™n gia l·∫≠p tr√¨nh Python v·ªõi 10 nƒÉm kinh nghi·ªám."
    },
    {
      "role": "user",
      "content": "Gi·∫£i th√≠ch v·ªÅ list comprehension"
    }
  ]
}
```

---

### 1.3. V·ªõi Conversation History

**Body:**
```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "system",
      "content": "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh v√† h·ªØu √≠ch."
    },
    {
      "role": "user",
      "content": "Python l√† g√¨?"
    },
    {
      "role": "assistant",
      "content": "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh b·∫≠c cao, d·ªÖ h·ªçc v√† m·∫°nh m·∫Ω, ƒë∆∞·ª£c t·∫°o b·ªüi Guido van Rossum."
    },
    {
      "role": "user",
      "content": "N√≥ c√≥ ·ª©ng d·ª•ng g√¨?"
    }
  ]
}
```

---

### 1.4. Y√™u C·∫ßu Code Generation

**Body:**
```json
{
  "model": "gemini-3.0-pro",
  "messages": [
    {
      "role": "system",
      "content": "B·∫°n l√† m·ªôt chuy√™n gia l·∫≠p tr√¨nh. H√£y vi·∫øt code s·∫°ch, c√≥ comment v√† follow best practices."
    },
    {
      "role": "user",
      "content": "Vi·∫øt function Python ƒë·ªÉ ki·ªÉm tra s·ªë nguy√™n t·ªë"
    }
  ]
}
```

---

### 1.5. Ph√¢n T√≠ch D·ªØ Li·ªáu

**Body:**
```json
{
  "model": "gemini-2.5-pro",
  "messages": [
    {
      "role": "system",
      "content": "B·∫°n l√† data analyst chuy√™n nghi·ªáp. Ph√¢n t√≠ch d·ªØ li·ªáu v√† ƒë∆∞a ra insights."
    },
    {
      "role": "user",
      "content": "Ph√¢n t√≠ch xu h∆∞·ªõng AI trong nƒÉm 2024"
    }
  ]
}
```

---

### 1.6. Multi-turn Conversation (Chat Bot)

**Request 1:**
```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "user",
      "content": "T√¥i mu·ªën h·ªçc l·∫≠p tr√¨nh web"
    }
  ]
}
```

**Request 2 (ti·∫øp theo):**
```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "user",
      "content": "T√¥i mu·ªën h·ªçc l·∫≠p tr√¨nh web"
    },
    {
      "role": "assistant",
      "content": "Tuy·ªát v·ªùi! T√¥i khuy√™n b·∫°n n√™n b·∫Øt ƒë·∫ßu v·ªõi HTML, CSS v√† JavaScript..."
    },
    {
      "role": "user",
      "content": "H·ªçc m·∫•t bao l√¢u?"
    }
  ]
}
```

---

### 1.7. S·ª≠ D·ª•ng Model M·∫°nh Nh·∫•t

**Body:**
```json
{
  "model": "gemini-3.0-pro",
  "messages": [
    {
      "role": "system",
      "content": "B·∫°n l√† chuy√™n gia v·ªÅ AI v√† machine learning."
    },
    {
      "role": "user",
      "content": "Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ transformer architecture"
    }
  ]
}
```

---

## 2. /gemini

T·∫°o **session m·ªõi** cho m·ªói request. Th√≠ch h·ª£p cho c√°c c√¢u h·ªèi ƒë·ªôc l·∫≠p.

### 2.1. Request C∆° B·∫£n

**Method:** `POST`  
**URL:** `http://localhost:6969/gemini`

**Body:**
```json
{
  "message": "Xin ch√†o! H√¥m nay th·∫ø n√†o?",
  "model": "gemini-2.5-flash"
}
```

**Response:**
```json
{
  "response": "Xin ch√†o! T√¥i l√† m·ªôt m√¥ h√¨nh AI n√™n kh√¥ng c√≥ tr·∫£i nghi·ªám v·ªÅ ng√†y th√°ng nh∆∞ con ng∆∞·ªùi..."
}
```

---

### 2.2. C√¢u H·ªèi Ki·∫øn Th·ª©c

**Body:**
```json
{
  "message": "Gi·∫£i th√≠ch v·ªÅ blockchain",
  "model": "gemini-2.5-pro"
}
```

---

### 2.3. Y√™u C·∫ßu S√°ng T·∫°o

**Body:**
```json
{
  "message": "Vi·∫øt m·ªôt c√¢u chuy·ªán ng·∫Øn v·ªÅ robot",
  "model": "gemini-3.0-pro"
}
```

---

### 2.4. T√≥m T·∫Øt VƒÉn B·∫£n

**Body:**
```json
{
  "message": "T√≥m t·∫Øt n·ªôi dung sau: [VƒÉn b·∫£n d√†i c·ªßa b·∫°n ·ªü ƒë√¢y...]",
  "model": "gemini-2.5-flash"
}
```

---

### 2.5. Gi·∫£i To√°n

**Body:**
```json
{
  "message": "Gi·∫£i ph∆∞∆°ng tr√¨nh: 2x + 5 = 15",
  "model": "gemini-2.5-pro"
}
```

---

## 3. /gemini-chat

Duy tr√¨ **session li√™n t·ª•c**. Th√≠ch h·ª£p cho cu·ªôc h·ªôi tho·∫°i nhi·ªÅu l∆∞·ª£t.

### 3.1. Request ƒê·∫ßu Ti√™n

**Method:** `POST`  
**URL:** `http://localhost:6969/gemini-chat`

**Body:**
```json
{
  "message": "T√¥i mu·ªën h·ªçc Python",
  "model": "gemini-2.5-flash"
}
```

**Response:**
```json
{
  "response": "Tuy·ªát v·ªùi! Python l√† m·ªôt l·ª±a ch·ªçn tuy·ªát v·ªùi ƒë·ªÉ b·∫Øt ƒë·∫ßu l·∫≠p tr√¨nh..."
}
```

---

### 3.2. Request Ti·∫øp Theo (C√πng Session)

**Body:**
```json
{
  "message": "T√¥i n√™n b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u?",
  "model": "gemini-2.5-flash"
}
```

**Response s·∫Ω d·ª±a tr√™n ng·ªØ c·∫£nh c√¢u h·ªèi tr∆∞·ªõc.**

---

### 3.3. Ti·∫øp T·ª•c Cu·ªôc H·ªôi Tho·∫°i

**Body:**
```json
{
  "message": "C√≤n v·ªÅ th∆∞ vi·ªán th√¨ sao?",
  "model": "gemini-2.5-flash"
}
```

---

### 3.4. Chat Bot Support

**Request 1:**
```json
{
  "message": "T√¥i g·∫∑p l·ªói khi c√†i ƒë·∫∑t package",
  "model": "gemini-2.5-pro"
}
```

**Request 2:**
```json
{
  "message": "L·ªói l√† 'ModuleNotFoundError'",
  "model": "gemini-2.5-pro"
}
```

**Request 3:**
```json
{
  "message": "T√¥i ƒë√£ th·ª≠ pip install nh∆∞ng kh√¥ng ƒë∆∞·ª£c",
  "model": "gemini-2.5-pro"
}
```

---

### 3.5. H·ªçc T·∫≠p T∆∞∆°ng T√°c

**Session h·ªçc Python:**

```json
// Request 1
{
  "message": "D·∫°y t√¥i v·ªÅ bi·∫øn trong Python",
  "model": "gemini-2.5-flash"
}

// Request 2
{
  "message": "Cho t√¥i v√≠ d·ª•",
  "model": "gemini-2.5-flash"
}

// Request 3
{
  "message": "C√≤n v·ªÅ ki·ªÉu d·ªØ li·ªáu th√¨ sao?",
  "model": "gemini-2.5-flash"
}
```

---

## 4. /translate

Endpoint ƒë·ªÉ d·ªãch thu·∫≠t. Duy tr√¨ session nh∆∞ `/gemini-chat`.

### 4.1. D·ªãch Anh ‚Üí Vi·ªát

**Method:** `POST`  
**URL:** `http://localhost:6969/translate`

**Body:**
```json
{
  "message": "Translate to Vietnamese: Hello, how are you today?",
  "model": "gemini-2.5-flash"
}
```

**Response:**
```json
{
  "response": "Xin ch√†o, h√¥m nay b·∫°n th·∫ø n√†o?"
}
```

---

### 4.2. D·ªãch Vi·ªát ‚Üí Anh

**Body:**
```json
{
  "message": "Translate to English: T√¥i ƒëang h·ªçc l·∫≠p tr√¨nh",
  "model": "gemini-2.5-flash"
}
```

---

### 4.3. D·ªãch VƒÉn B·∫£n D√†i

**Body:**
```json
{
  "message": "Translate to Vietnamese: Artificial Intelligence is revolutionizing the way we live and work. Machine learning algorithms can now process vast amounts of data...",
  "model": "gemini-2.5-pro"
}
```

---

### 4.4. D·ªãch Code Comments

**Body:**
```json
{
  "message": "Translate Python comments to Vietnamese:\n\n# Initialize the variable\nx = 10\n\n# Loop through the list\nfor item in items:\n    print(item)",
  "model": "gemini-2.5-flash"
}
```

---

### 4.5. D·ªãch Chuy√™n Ng√†nh

**Body:**
```json
{
  "message": "Translate to Vietnamese (technical terms): The RESTful API uses HTTP methods to perform CRUD operations on resources.",
  "model": "gemini-2.5-pro"
}
```

---

## 5. /v1beta/models/{model}

**Google Generative AI v1beta API** compatible endpoint.

### 5.1. Gemini 2.5 Flash

**Method:** `POST`  
**URL:** `http://localhost:6969/v1beta/models/gemini-2.5-flash`

**Body:**
```json
{
  "contents": [
    {
      "parts": [
        {
          "text": "Gi·∫£i th√≠ch v·ªÅ Docker"
        }
      ]
    }
  ]
}
```

---

### 5.2. Gemini 2.5 Pro

**URL:** `http://localhost:6969/v1beta/models/gemini-2.5-pro`

**Body:**
```json
{
  "contents": [
    {
      "parts": [
        {
          "text": "Ph√¢n t√≠ch ki·∫øn tr√∫c microservices"
        }
      ]
    }
  ]
}
```

---

### 5.3. Gemini 3.0 Pro

**URL:** `http://localhost:6969/v1beta/models/gemini-3.0-pro`

**Body:**
```json
{
  "contents": [
    {
      "parts": [
        {
          "text": "Explain quantum computing in detail"
        }
      ]
    }
  ]
}
```

---

### 5.4. Multi-part Content

**Body:**
```json
{
  "contents": [
    {
      "parts": [
        {
          "text": "Ph·∫ßn 1: Gi·ªõi thi·ªáu v·ªÅ AI"
        },
        {
          "text": "Ph·∫ßn 2: ·ª®ng d·ª•ng c·ªßa AI"
        }
      ]
    }
  ]
}
```

---

### 5.5. Complex Query

**Body:**
```json
{
  "contents": [
    {
      "parts": [
        {
          "text": "Ph√¢n t√≠ch v√† so s√°nh: \n1. React vs Vue.js\n2. Performance\n3. Ecosystem\n4. Learning curve\n5. Use cases"
        }
      ]
    }
  ]
}
```

---

## Postman Collection

### C·∫•u H√¨nh Environment

**Environment Name:** `WebAI-Local`

**Variables:**
```
base_url: http://localhost:6969
default_model: gemini-2.5-flash
pro_model: gemini-2.5-pro
best_model: gemini-3.0-pro
```

### S·ª≠ D·ª•ng Variables

**URL:**
```
{{base_url}}/v1/chat/completions
```

**Body:**
```json
{
  "model": "{{default_model}}",
  "messages": [...]
}
```

---

## Tests Scripts cho Postman

### Script 1: Ki·ªÉm Tra Status Code

Th√™m v√†o tab **Tests**:

```javascript
pm.test("Status code is 200", function () {
    pm.response.to.have.status(200);
});
```

---

### Script 2: Ki·ªÉm Tra Response Structure

```javascript
pm.test("Response has choices array", function () {
    var jsonData = pm.response.json();
    pm.expect(jsonData.choices).to.be.an('array');
});

pm.test("Response has content", function () {
    var jsonData = pm.response.json();
    pm.expect(jsonData.choices[0].message.content).to.exist;
    pm.expect(jsonData.choices[0].message.content.length).to.be.above(0);
});
```

---

### Script 3: Log Response Time

```javascript
pm.test("Response time is less than 10s", function () {
    pm.expect(pm.response.responseTime).to.be.below(10000);
});

console.log("Response time: " + pm.response.responseTime + "ms");
```

---

### Script 4: Extract v√† Log Content

```javascript
// Extract response
var jsonData = pm.response.json();
var content = jsonData.choices[0].message.content;

// Log to console
console.log("=== AI Response ===");
console.log(content);
console.log("=== End Response ===");

// Save to environment (ƒë·ªÉ s·ª≠ d·ª•ng trong request ti·∫øp theo)
pm.environment.set("last_response", content);
```

---

### Script 5: Validate Model

```javascript
pm.test("Correct model used", function () {
    var jsonData = pm.response.json();
    var requestedModel = pm.request.body.raw ? 
        JSON.parse(pm.request.body.raw).model : 
        pm.environment.get("default_model");
    
    pm.expect(jsonData.model).to.eql(requestedModel);
});
```

---

## Pre-request Scripts

### Script 1: Add Timestamp

```javascript
pm.environment.set("timestamp", new Date().toISOString());
console.log("Request sent at: " + pm.environment.get("timestamp"));
```

---

### Script 2: Random Model Selection

```javascript
const models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3.0-pro"];
const randomModel = models[Math.floor(Math.random() * models.length)];
pm.environment.set("random_model", randomModel);
console.log("Using model: " + randomModel);
```

---

## Import Collection v√†o Postman

### T·∫°o Collection JSON

T·∫°o file `WebAI-API-Collection.json`:

```json
{
  "info": {
    "name": "WebAI-to-API",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "Chat Completions",
      "request": {
        "method": "POST",
        "header": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"model\": \"{{default_model}}\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Xin ch√†o!\"\n    }\n  ]\n}"
        },
        "url": {
          "raw": "{{base_url}}/v1/chat/completions",
          "host": ["{{base_url}}"],
          "path": ["v1", "chat", "completions"]
        }
      }
    },
    {
      "name": "Gemini - New Session",
      "request": {
        "method": "POST",
        "header": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"message\": \"Xin ch√†o!\",\n  \"model\": \"{{default_model}}\"\n}"
        },
        "url": {
          "raw": "{{base_url}}/gemini",
          "host": ["{{base_url}}"],
          "path": ["gemini"]
        }
      }
    },
    {
      "name": "Gemini Chat - Persistent",
      "request": {
        "method": "POST",
        "header": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"message\": \"Ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán\",\n  \"model\": \"{{default_model}}\"\n}"
        },
        "url": {
          "raw": "{{base_url}}/gemini-chat",
          "host": ["{{base_url}}"],
          "path": ["gemini-chat"]
        }
      }
    },
    {
      "name": "Translate",
      "request": {
        "method": "POST",
        "header": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"message\": \"Translate to Vietnamese: Hello world\",\n  \"model\": \"{{default_model}}\"\n}"
        },
        "url": {
          "raw": "{{base_url}}/translate",
          "host": ["{{base_url}}"],
          "path": ["translate"]
        }
      }
    }
  ]
}
```

### Import v√†o Postman

1. M·ªü Postman
2. Click **Import**
3. Ch·ªçn file `WebAI-API-Collection.json`
4. Click **Import**

---

## Tips & Best Practices

### 1. Ch·ªçn Model Ph√π H·ª£p

- **C√¢u h·ªèi ƒë∆°n gi·∫£n, chat**: `gemini-2.5-flash`
- **Ph√¢n t√≠ch, l√Ω lu·∫≠n**: `gemini-2.5-pro`
- **Tasks ph·ª©c t·∫°p, quan tr·ªçng**: `gemini-3.0-pro`

### 2. T·ªëi ∆Øu Response Time

- S·ª≠ d·ª•ng model nhanh h∆°n cho simple tasks
- Gi·ªØ messages ng·∫Øn g·ªçn
- Tr√°nh g·ª≠i qu√° nhi·ªÅu conversation history

### 3. Error Handling

Ki·ªÉm tra status codes:
- `200` - Success
- `400` - Bad request (ki·ªÉm tra body)
- `503` - Service unavailable (server ch∆∞a ready)
- `500` - Internal error

### 4. Organizing Collections

T·∫°o folders trong Collection:
- `Basic Queries`
- `Conversation`
- `Code Generation`
- `Translation`
- `Advanced`

---

**Ch√∫c b·∫°n test API th√†nh c√¥ng! üöÄ**
